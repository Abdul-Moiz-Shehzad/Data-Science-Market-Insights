{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>...</th>\n",
       "      <th>Machine Learning</th>\n",
       "      <th>SQL</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Big Data/Spark</th>\n",
       "      <th>Visualization Tool</th>\n",
       "      <th>Data Science</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Grade Required</th>\n",
       "      <th>Company Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>$38.00 - $45.00 Per Hour (Employer est.)</td>\n",
       "      <td>Minimum three years experience in data science...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>J &amp; S Consulting</td>\n",
       "      <td>Tucker, GA</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>--</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$120K - $130K (Employer est.)</td>\n",
       "      <td>Data science: 1 year (Preferred). Expertise in...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>element technologies</td>\n",
       "      <td>Remote</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>2000</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$66.82 - $80.54 Per Hour (Employer est.)</td>\n",
       "      <td>End-to-end data and model pipeline deployment ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Boston Technology</td>\n",
       "      <td>Malvern, PA</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>2004</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>$105K - $160K (Employer est.)</td>\n",
       "      <td>Communicates technical concepts to non-technic...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Costco Wholesale</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1976</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>General Merchandise &amp; Superstores</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Co-Op</td>\n",
       "      <td>$84K - $109K (Glassdoor est.)</td>\n",
       "      <td>Work with source control tools like GIT to sav...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Hunter Engineering Company</td>\n",
       "      <td>Bridgeton, MO</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>1946</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Machinery Manufacturing</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Job Title                           Salary Estimate  \\\n",
       "0      Data Analytics  $38.00 - $45.00 Per Hour (Employer est.)   \n",
       "1      Data Scientist             $120K - $130K (Employer est.)   \n",
       "2      Data Scientist  $66.82 - $80.54 Per Hour (Employer est.)   \n",
       "3       Data Engineer             $105K - $160K (Employer est.)   \n",
       "4  Data Science Co-Op             $84K - $109K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Minimum three years experience in data science...     3.9   \n",
       "1  Data science: 1 year (Preferred). Expertise in...     4.0   \n",
       "2  End-to-end data and model pipeline deployment ...     4.4   \n",
       "3  Communicates technical concepts to non-technic...     3.9   \n",
       "4  Work with source control tools like GIT to sav...     4.1   \n",
       "\n",
       "                 Company Name       Location                    Size Founded  \\\n",
       "0            J & S Consulting     Tucker, GA     51 to 200 Employees      --   \n",
       "1        element technologies         Remote     51 to 200 Employees    2000   \n",
       "2           Boston Technology    Malvern, PA     51 to 200 Employees    2004   \n",
       "3            Costco Wholesale     Dallas, TX        10000+ Employees    1976   \n",
       "4  Hunter Engineering Company  Bridgeton, MO  1001 to 5000 Employees    1946   \n",
       "\n",
       "   Type of ownership                                 Industry  ...  \\\n",
       "0  Company - Private  Information Technology Support Services  ...   \n",
       "1  Company - Private  Information Technology Support Services  ...   \n",
       "2  Company - Private  Information Technology Support Services  ...   \n",
       "3   Company - Public        General Merchandise & Superstores  ...   \n",
       "4  Company - Private                  Machinery Manufacturing  ...   \n",
       "\n",
       "  Machine Learning SQL Computer Science  Deep Learning  Big Data/Spark  \\\n",
       "0                0   1                0              0               0   \n",
       "1                1   0                0              0               0   \n",
       "2                1   0                0              0               1   \n",
       "3                1   0                0              0               0   \n",
       "4                1   0                1              0               0   \n",
       "\n",
       "   Visualization Tool  Data Science  Experience  Grade Required Company Age  \n",
       "0                   0             1           3               0          -1  \n",
       "1                   0             1           1               0          24  \n",
       "2                   0             0          -1               0          20  \n",
       "3                   0             0          -1               0          48  \n",
       "4                   0             0          -1               1          78  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv(\"Data Science Jobs preprocessed.csv\")\n",
    "df=pd.read_csv(\"Data Science Jobs MAYBE.csv\")\n",
    "df.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "df2.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Size</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Employeer Estimate</th>\n",
       "      <th>State</th>\n",
       "      <th>Company Age</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Machine Learning</th>\n",
       "      <th>SQL</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Deep Learning</th>\n",
       "      <th>Big Data/Spark</th>\n",
       "      <th>Visualization Tool</th>\n",
       "      <th>Data Science</th>\n",
       "      <th>Seniority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83000.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$5 to $25 million (USD)</td>\n",
       "      <td>1</td>\n",
       "      <td>GA</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>1</td>\n",
       "      <td>Remote</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147360.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>51 to 200 Employees</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Information Technology Support Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$5 to $25 million (USD)</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132500.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>General Merchandise &amp; Superstores</td>\n",
       "      <td>Retail &amp; Wholesale</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mid-Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96500.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Machinery Manufacturing</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>$500 million to $1 billion (USD)</td>\n",
       "      <td>0</td>\n",
       "      <td>ID</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Applicable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Salary  Rating                    Size  Type of ownership  \\\n",
       "0         83000.0     3.9     51 to 200 Employees  Company - Private   \n",
       "1        125000.0     4.0     51 to 200 Employees  Company - Private   \n",
       "2        147360.0     4.4     51 to 200 Employees  Company - Private   \n",
       "3        132500.0     3.9        10000+ Employees   Company - Public   \n",
       "4         96500.0     4.1  1001 to 5000 Employees  Company - Private   \n",
       "\n",
       "                                  Industry                  Sector  \\\n",
       "0  Information Technology Support Services  Information Technology   \n",
       "1  Information Technology Support Services  Information Technology   \n",
       "2  Information Technology Support Services  Information Technology   \n",
       "3        General Merchandise & Superstores      Retail & Wholesale   \n",
       "4                  Machinery Manufacturing           Manufacturing   \n",
       "\n",
       "                            Revenue  Employeer Estimate   State  Company Age  \\\n",
       "0           $5 to $25 million (USD)                   1      GA           -1   \n",
       "1          Unknown / Non-Applicable                   1  Remote           24   \n",
       "2           $5 to $25 million (USD)                   1      AL           20   \n",
       "3          Unknown / Non-Applicable                   1      AL           48   \n",
       "4  $500 million to $1 billion (USD)                   0      ID           78   \n",
       "\n",
       "   Analysis  Machine Learning  SQL  Computer Science  Deep Learning  \\\n",
       "0         0                 0    1                 0              0   \n",
       "1         0                 1    0                 0              0   \n",
       "2         0                 1    0                 0              0   \n",
       "3         0                 1    0                 0              0   \n",
       "4         0                 1    0                 1              0   \n",
       "\n",
       "   Big Data/Spark  Visualization Tool  Data Science       Seniority  \n",
       "0               0                   0             1  Not Applicable  \n",
       "1               0                   0             1       Mid-Level  \n",
       "2               1                   0             0       Mid-Level  \n",
       "3               0                   0             0       Mid-Level  \n",
       "4               0                   0             0  Not Applicable  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[[\"Average Salary\",\"Rating\",\"Size\",\"Type of ownership\",\"Industry\",\"Sector\",\"Revenue\",\"Employeer Estimate\",\"State\",\"Company Age\",'Analysis','Machine Learning', 'SQL', 'Computer Science', 'Deep Learning','Big Data/Spark', 'Visualization Tool', 'Data Science',\"Seniority\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "scaler_features = StandardScaler()\n",
    "scaler_target = StandardScaler()\n",
    "\n",
    "df['Company Age'] = scaler_features.fit_transform(df['Company Age'].values.reshape(-1, 1))\n",
    "df['Rating'] = scaler_features.fit_transform(df['Rating'].values.reshape(-1, 1))\n",
    "df['Average Salary'] = scaler_target.fit_transform(df['Average Salary'].values.reshape(-1, 1))\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df = pd.get_dummies(df, dtype=int)\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df.drop(columns=['Average Salary'])\n",
    "y = df['Average Salary']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MSE: 2082744134.0594542\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Train Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)  # Adjust alpha for regularization strength\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Inverse-transform predictions for interpretation\n",
    "y_test_original = scaler_target.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "y_pred_original = scaler_target.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "print(f\"Ridge Regression MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Employeer Estimate', 'Company Age', 'Analysis', 'Machine Learning',\n",
      "       'SQL', 'Computer Science', 'Deep Learning', 'Big Data/Spark',\n",
      "       'Visualization Tool', 'Data Science', 'Size_51 to 200 Employees',\n",
      "       'Type of ownership_Company - Private',\n",
      "       'Type of ownership_Company - Public',\n",
      "       'Type of ownership_Nonprofit Organization',\n",
      "       'Industry_Health Care Services & Hospitals', 'Sector_Healthcare',\n",
      "       'Sector_Information Technology',\n",
      "       'Sector_Pharmaceutical & Biotechnology',\n",
      "       'Sector_Transportation & Logistics', 'Revenue_$1 to $5 billion (USD)',\n",
      "       'Revenue_$10+ billion (USD)', 'Revenue_Unknown / Non-Applicable',\n",
      "       'State_AK', 'State_AL', 'State_CA', 'State_NE', 'State_United States',\n",
      "       'State_WA', 'Seniority_Junior', 'Seniority_Manager/Leadership',\n",
      "       'Seniority_Mid-Level', 'Seniority_Senior'],\n",
      "      dtype='object')\n",
      "Lasso Regression MSE: 2164890279.165968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Train Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.01)  # Adjust alpha for regularization strength\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Print selected features\n",
    "selected_features = X.columns[(lasso_model.coef_ != 0)]\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# Evaluate Lasso Model\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Inverse-transform predictions\n",
    "y_pred_original_lasso = scaler_target.inverse_transform(y_pred_lasso.reshape(-1, 1))\n",
    "mse_lasso = mean_squared_error(y_test_original, y_pred_original_lasso)\n",
    "print(f\"Lasso Regression MSE: {mse_lasso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso and Ridge Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge with Lasso-selected Features MSE: 2194872221.3769855\n"
     ]
    }
   ],
   "source": [
    "# Subset dataset with Lasso-selected features\n",
    "selected_features_lasso = [\n",
    "    'Employeer Estimate', 'Company Age', 'Analysis', 'Machine Learning', 'SQL',\n",
    "    'Computer Science', 'Deep Learning', 'Big Data/Spark', 'Visualization Tool',\n",
    "    'Data Science', 'Size_51 to 200 Employees',\n",
    "    'Type of ownership_Company - Private', 'Type of ownership_Company - Public',\n",
    "    'Type of ownership_Nonprofit Organization',\n",
    "    'Industry_Health Care Services & Hospitals', 'Sector_Healthcare',\n",
    "    'Sector_Information Technology', 'Sector_Pharmaceutical & Biotechnology',\n",
    "    'Sector_Transportation & Logistics', 'Revenue_$1 to $5 billion (USD)',\n",
    "    'Revenue_$10+ billion (USD)', 'Revenue_Unknown / Non-Applicable',\n",
    "    'State_AK', 'State_AL', 'State_CA', 'State_NE', 'State_United States',\n",
    "    'State_WA', 'Seniority_Junior', 'Seniority_Manager/Leadership',\n",
    "    'Seniority_Mid-Level', 'Seniority_Senior'\n",
    "]\n",
    "X_train_subset = X_train[selected_features_lasso]\n",
    "X_test_subset = X_test[selected_features_lasso]\n",
    "\n",
    "ridge_model_subset = Ridge(alpha=1.0)\n",
    "ridge_model_subset.fit(X_train_subset, y_train)\n",
    "y_pred_subset = ridge_model_subset.predict(X_test_subset)\n",
    "\n",
    "mse_subset = mean_squared_error(\n",
    "    scaler_target.inverse_transform(y_test.values.reshape(-1, 1)),\n",
    "    scaler_target.inverse_transform(y_pred_subset.reshape(-1, 1))\n",
    ")\n",
    "print(f\"Ridge with Lasso-selected Features MSE: {mse_subset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: -0.0689\n",
      "Employeer Estimate: 0.3282\n",
      "Company Age: -0.0946\n",
      "Analysis: -0.0692\n",
      "Machine Learning: 0.1897\n",
      "SQL: -0.1722\n",
      "Computer Science: 0.1457\n",
      "Deep Learning: 0.0309\n",
      "Big Data/Spark: 0.1161\n",
      "Visualization Tool: -0.2590\n",
      "Data Science: -0.0317\n",
      "Size_-1: -0.2444\n",
      "Size_1 to 50 Employees: -0.0145\n",
      "Size_10000+ Employees: -0.1204\n",
      "Size_1001 to 5000 Employees: 0.1105\n",
      "Size_201 to 500 Employees: 0.2939\n",
      "Size_5001 to 10000 Employees: 0.0712\n",
      "Size_501 to 1000 Employees: 0.1482\n",
      "Size_51 to 200 Employees: -0.2608\n",
      "Size_Unknown: 0.0163\n",
      "Type of ownership_-1: -0.2444\n",
      "Type of ownership_College / University: -0.0230\n",
      "Type of ownership_Company - Private: 0.1691\n",
      "Type of ownership_Company - Public: 0.0414\n",
      "Type of ownership_Government: -0.1729\n",
      "Type of ownership_Hospital: 0.8271\n",
      "Type of ownership_Nonprofit Organization: -0.5837\n",
      "Type of ownership_Private Practice / Firm: -0.2780\n",
      "Type of ownership_School / School District: 0.0928\n",
      "Type of ownership_Self-employed: 0.0404\n",
      "Type of ownership_Subsidiary or Business Segment: 0.1061\n",
      "Type of ownership_Unknown: 0.0250\n",
      "Industry_--: 0.0467\n",
      "Industry_-1: -0.2444\n",
      "Industry_Accounting & Tax: 0.0644\n",
      "Industry_Advertising & Public Relations: 0.0703\n",
      "Industry_Aerospace & Defense: -0.0966\n",
      "Industry_Airlines, Airports & Air Transportation: -0.5465\n",
      "Industry_Banking & Lending: 0.1257\n",
      "Industry_Beauty & Personal Accessories Stores: 0.0103\n",
      "Industry_Beauty & Wellness: -0.2995\n",
      "Industry_Biotech & Pharmaceuticals: 0.1877\n",
      "Industry_Broadcast Media: -0.1216\n",
      "Industry_Business Consulting: 0.0618\n",
      "Industry_Car & Truck Rental: 0.2878\n",
      "Industry_Chemical Manufacturing: -0.4038\n",
      "Industry_Civic & Social Services: -0.2484\n",
      "Industry_Colleges & Universities: -0.0019\n",
      "Industry_Commercial Equipment Services: 0.1522\n",
      "Industry_Computer Hardware Development: 0.1537\n",
      "Industry_Construction: 0.0000\n",
      "Industry_Consumer Product Manufacturing: -0.0548\n",
      "Industry_Department, Clothing & Shoe Stores: 0.3730\n",
      "Industry_Electronics Manufacturing: 0.4392\n",
      "Industry_Energy & Utilities: 0.1184\n",
      "Industry_Enterprise Software & Network Solutions: 0.1573\n",
      "Industry_Film Production: -0.0268\n",
      "Industry_Financial Transaction Processing: 0.0266\n",
      "Industry_Food & Beverage Manufacturing: 0.1144\n",
      "Industry_General Merchandise & Superstores: -0.0510\n",
      "Industry_Grocery Stores: 0.0000\n",
      "Industry_HR Consulting: 0.1306\n",
      "Industry_Health Care Services & Hospitals: 0.1587\n",
      "Industry_Home Furniture & Housewares Stores: 0.5078\n",
      "Industry_Hotels & Resorts: -0.1260\n",
      "Industry_Information Technology Support Services: -0.1102\n",
      "Industry_Insurance Agencies & Brokerages: 0.1897\n",
      "Industry_Insurance Carriers: -0.1783\n",
      "Industry_Internet & Web Services: 0.0408\n",
      "Industry_Investment & Asset Management: -0.1408\n",
      "Industry_Legal: -0.1792\n",
      "Industry_Machinery Manufacturing: -0.2694\n",
      "Industry_Membership Organizations: -0.2274\n",
      "Industry_Metal & Mineral Manufacturing: 0.0934\n",
      "Industry_National Agencies: -0.0194\n",
      "Industry_Other Retail Stores: -0.5554\n",
      "Industry_Pet & Pet Supplies Stores: -0.6711\n",
      "Industry_Pharmaceutical: 0.0845\n",
      "Industry_Preschools & Child Care Services: -0.1838\n",
      "Industry_Primary & Secondary Schools: -0.0084\n",
      "Industry_Publishing: -0.2245\n",
      "Industry_Real Estate: -0.0419\n",
      "Industry_Research & Development: 0.0277\n",
      "Industry_Restaurants & Cafes: 0.0177\n",
      "Industry_Shipping & Trucking: 0.0669\n",
      "Industry_Software Development: 0.1143\n",
      "Industry_Sporting Goods Stores: 0.0647\n",
      "Industry_Sports & Recreation: 0.1608\n",
      "Industry_State & Regional Agencies: -0.2211\n",
      "Industry_Stock Exchanges: 0.1304\n",
      "Industry_Telecommunications Services: 0.0015\n",
      "Industry_Transportation Equipment Manufacturing: 0.3092\n",
      "Industry_Video Game Publishing: 0.4670\n",
      "Industry_Wholesale: 0.2968\n",
      "Sector_--: 0.0467\n",
      "Sector_-1: -0.2444\n",
      "Sector_Aerospace & Defense: -0.0966\n",
      "Sector_Arts, Entertainment & Recreation: 0.1608\n",
      "Sector_Construction, Repair & Maintenance Services: 0.1522\n",
      "Sector_Education: -0.1940\n",
      "Sector_Energy, Mining & Utilities: 0.1184\n",
      "Sector_Financial Services: 0.2063\n",
      "Sector_Government & Public Administration: -0.2405\n",
      "Sector_Healthcare: 0.1587\n",
      "Sector_Hotels & Travel Accommodation: -0.1260\n",
      "Sector_Human Resources & Staffing: 0.1306\n",
      "Sector_Information Technology: 0.3559\n",
      "Sector_Insurance: 0.0114\n",
      "Sector_Legal: -0.1792\n",
      "Sector_Management & Consulting: -0.1379\n",
      "Sector_Manufacturing: 0.2282\n",
      "Sector_Media & Communication: 0.1645\n",
      "Sector_Nonprofit & NGO: -0.2484\n",
      "Sector_Personal Consumer Services: -0.2995\n",
      "Sector_Pharmaceutical & Biotechnology: 0.2722\n",
      "Sector_Real Estate: -0.0419\n",
      "Sector_Restaurants & Food Service: 0.0177\n",
      "Sector_Retail & Wholesale: -0.0249\n",
      "Sector_Telecommunications: 0.0015\n",
      "Sector_Transportation & Logistics: -0.1918\n",
      "Revenue_$1 to $5 billion (USD): 0.2694\n",
      "Revenue_$10+ billion (USD): 0.3173\n",
      "Revenue_$100 to $500 million (USD): -0.1818\n",
      "Revenue_$25 to $100 million (USD): -0.0717\n",
      "Revenue_$5 to $10 billion (USD): 0.1710\n",
      "Revenue_$5 to $25 million (USD): 0.0941\n",
      "Revenue_$500 million to $1 billion (USD): -0.4402\n",
      "Revenue_-1: -0.2444\n",
      "Revenue_Less than $1 million (USD): 0.0000\n",
      "Revenue_Unknown / Non-Applicable: 0.0863\n",
      "State_AK: 0.9219\n",
      "State_AL: 0.5412\n",
      "State_AR: 0.0020\n",
      "State_AZ: -0.3102\n",
      "State_CA: 0.4509\n",
      "State_CO: -0.2663\n",
      "State_CT: 0.8855\n",
      "State_DE: 0.1722\n",
      "State_FL: -0.1401\n",
      "State_GA: -0.2847\n",
      "State_HI: -0.2173\n",
      "State_IA: 0.1260\n",
      "State_ID: -0.0857\n",
      "State_IL: -0.0826\n",
      "State_IN: 0.1349\n",
      "State_KY: -0.1628\n",
      "State_LA: -0.5706\n",
      "State_MA: 0.3995\n",
      "State_MN: -0.2974\n",
      "State_MO: -0.1209\n",
      "State_NE: 0.2058\n",
      "State_NJ: 0.3707\n",
      "State_NY: -0.1631\n",
      "State_OH: -0.5564\n",
      "State_OR: -0.0800\n",
      "State_PA: -0.8452\n",
      "State_RI: 0.3117\n",
      "State_Remote: 0.0911\n",
      "State_TX: -0.1731\n",
      "State_UT: -0.9160\n",
      "State_United States: 0.3523\n",
      "State_VA: 0.0830\n",
      "State_WA: 0.2239\n",
      "Seniority_Junior: -0.5495\n",
      "Seniority_Manager/Leadership: 0.4468\n",
      "Seniority_Mid-Level: -0.1543\n",
      "Seniority_Not Applicable: 0.0310\n",
      "Seniority_Senior: 0.2260\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ridge coefficients\n",
    "coefficients = ridge_model.coef_\n",
    "features = X.columns\n",
    "for feature, coef in zip(features, coefficients):\n",
    "    print(f\"{feature}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Ridge: {'alpha': 10.0}\n",
      "Best CV MSE for Ridge: 0.7085077279733618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ridge cross-validation for alpha\n",
    "ridge_params = {'alpha': np.logspace(-3, 3, 7)}\n",
    "ridge_cv = GridSearchCV(Ridge(), ridge_params, scoring='neg_mean_squared_error', cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha for Ridge:\", ridge_cv.best_params_)\n",
    "print(\"Best CV MSE for Ridge:\", -ridge_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression RMSE: 45637.09164768778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "print(f\"Ridge Regression RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting RMSE: 0.9442989515920165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Gradient Boosting\n",
    "gbr = GradientBoostingRegressor(n_estimators=500, learning_rate=0.05, max_depth=4, random_state=42)\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and RMSE\n",
    "y_pred_gbr = gbr.predict(X_test)\n",
    "rmse_gbr = np.sqrt(mean_squared_error(y_test, y_pred_gbr))\n",
    "print(f\"Gradient Boosting RMSE: {rmse_gbr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 1000}\n",
      "Best Gradient Boosting RMSE: 0.856794544747574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best Gradient Boosting RMSE:\", np.sqrt(-grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 0.8873227588057296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=500, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and RMSE\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"Random Forest RMSE: {rmse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Best Random Forest RMSE: 0.8512617188857754\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_rf.best_params_)\n",
    "print(\"Best Random Forest RMSE:\", np.sqrt(-grid_search_rf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing the random forest on original scale because of improved rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE (original scale): 43204.42712339326\n"
     ]
    }
   ],
   "source": [
    "# Invert scaling for predictions\n",
    "y_pred_rf_original = mms2.inverse_transform(rf.predict(X_test).reshape(-1, 1))\n",
    "y_test_original = mms2.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Calculate RMSE on the original scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "rmse_rf_original = np.sqrt(mean_squared_error(y_test_original, y_pred_rf_original))\n",
    "print(f\"Random Forest RMSE (original scale): {rmse_rf_original}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Salary: [[170096.59877771]]\n"
     ]
    }
   ],
   "source": [
    "mean_salary = df[\"Average Salary\"].mean()\n",
    "print(f\"Mean Salary: {mms2.inverse_transform(mean_salary.reshape(-1, 1))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is already giving a solid performance with a 25% relative RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter randomized Search in Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 1000, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [500, 1000, 1500],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE (original scale): 0.8893060239010974\n"
     ]
    }
   ],
   "source": [
    "y_pred_rs = random_search.predict(X_test)\n",
    "mse= np.sqrt(mean_squared_error(y_test, y_pred_rs))\n",
    "print(f\"Random Forest RMSE (original scale): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE (original scale): 43300.99382522621\n"
     ]
    }
   ],
   "source": [
    "# Invert scaling for predictions\n",
    "y_pred_rs_original = mms2.inverse_transform(random_search.predict(X_test).reshape(-1, 1))\n",
    "y_test_original = mms2.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Calculate RMSE on the original scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "rmse_rf_original = np.sqrt(mean_squared_error(y_test_original, y_pred_rs_original))\n",
    "print(f\"Random Forest RMSE (original scale): {rmse_rf_original}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\testr\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\testr\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\testr\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 1000, 'subsample': 0.8}\n",
      "XGBoost RMSE: 0.9164216578690574\n",
      "Predicted Salary Mean (original scale): 0.08126695\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df is your DataFrame and already processed as per the previous steps\n",
    "# Scaling the target (Average Salary) if needed\n",
    "mms_salary = StandardScaler()\n",
    "df['Average Salary'] = mms_salary.fit_transform(df[['Average Salary']])\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop(columns=['Average Salary'], axis=1)  # Drop target column\n",
    "y = df['Average Salary']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.01)\n",
    "\n",
    "# Hyperparameter tuning (GridSearchCV)\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [500, 1000],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Perform GridSearch\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model performance\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters for XGBoost:\", best_params)\n",
    "\n",
    "# Train the best model\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Inverse transform salary predictions (back to original scale)\n",
    "y_pred_original = mms_salary.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"XGBoost RMSE: {rmse}\")\n",
    "\n",
    "# For predicted salary values (inverse transformation)\n",
    "print(\"Predicted Salary Mean (original scale):\", y_pred_original.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['Employeer Estimate', 'Machine Learning', 'SQL', 'Computer Science',\n",
      "       'Big Data/Spark', 'Visualization Tool', 'Size_10000+ Employees',\n",
      "       'Size_5001 to 10000 Employees', 'Size_51 to 200 Employees',\n",
      "       'Size_Unknown', 'Type of ownership_Company - Private',\n",
      "       'Type of ownership_Government', 'Type of ownership_Hospital',\n",
      "       'Type of ownership_Nonprofit Organization',\n",
      "       'Type of ownership_School / School District',\n",
      "       'Type of ownership_Self-employed', 'Type of ownership_Unknown',\n",
      "       'Industry_--', 'Industry_-1', 'Industry_Accounting & Tax',\n",
      "       'Industry_Airlines, Airports & Air Transportation',\n",
      "       'Industry_Banking & Lending', 'Industry_Beauty & Wellness',\n",
      "       'Industry_Biotech & Pharmaceuticals', 'Industry_Business Consulting',\n",
      "       'Industry_Car & Truck Rental', 'Industry_Chemical Manufacturing',\n",
      "       'Industry_Computer Hardware Development', 'Industry_Construction',\n",
      "       'Industry_Electronics Manufacturing', 'Industry_Grocery Stores',\n",
      "       'Industry_HR Consulting', 'Industry_Health Care Services & Hospitals',\n",
      "       'Industry_Home Furniture & Housewares Stores',\n",
      "       'Industry_Hotels & Resorts', 'Industry_Machinery Manufacturing',\n",
      "       'Industry_Pet & Pet Supplies Stores', 'Industry_Pharmaceutical',\n",
      "       'Industry_Real Estate', 'Industry_Software Development',\n",
      "       'Industry_Sports & Recreation', 'Industry_Video Game Publishing',\n",
      "       'Industry_Wholesale', 'Sector_--', 'Sector_-1',\n",
      "       'Sector_Aerospace & Defense',\n",
      "       'Sector_Government & Public Administration',\n",
      "       'Sector_Hotels & Travel Accommodation', 'Sector_Information Technology',\n",
      "       'Sector_Insurance', 'Sector_Manufacturing',\n",
      "       'Sector_Personal Consumer Services',\n",
      "       'Sector_Pharmaceutical & Biotechnology', 'Sector_Real Estate',\n",
      "       'Sector_Retail & Wholesale', 'Sector_Transportation & Logistics',\n",
      "       'Revenue_$10+ billion (USD)', 'Revenue_$5 to $25 million (USD)',\n",
      "       'Revenue_$500 million to $1 billion (USD)',\n",
      "       'Revenue_Less than $1 million (USD)',\n",
      "       'Revenue_Unknown / Non-Applicable', 'State_AK', 'State_AL', 'State_AZ',\n",
      "       'State_CA', 'State_CT', 'State_DE', 'State_FL', 'State_HI', 'State_LA',\n",
      "       'State_MA', 'State_MN', 'State_NE', 'State_OH', 'State_PA', 'State_RI',\n",
      "       'State_United States', 'State_VA', 'State_WA', 'Seniority_Junior',\n",
      "       'Seniority_Manager/Leadership', 'Seniority_Mid-Level',\n",
      "       'Seniority_Not Applicable', 'Seniority_Senior'],\n",
      "      dtype='object')\n",
      "Forward Selection MSE: 8.324453467208558e+19\n"
     ]
    }
   ],
   "source": [
    "#df=df[[\"Average Salary\",\"Rating\",\"Size\",\"Type of ownership\",\"Industry\",\"Sector\",\"Revenue\",\"Employeer Estimate\",\"State\",\"Company Age\",'Analysis','Machine Learning', 'SQL', 'Computer Science', 'Deep Learning','Big Data/Spark', 'Visualization Tool', 'Data Science',\"Seniority\"]]\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop(columns=['Average Salary'],axis=1)  # Drop non-numeric/irrelevant columns\n",
    "y = df['Average Salary']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Forward Selection\n",
    "linear_regressor = LinearRegression()\n",
    "forward_selector = SequentialFeatureSelector(linear_regressor, n_features_to_select=\"auto\", direction=\"forward\", scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "forward_selector.fit(X_train, y_train)\n",
    "\n",
    "# Selected Features\n",
    "selected_features = X_train.columns[forward_selector.get_support()]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Evaluate the model with selected features\n",
    "X_train_selected = forward_selector.transform(X_train)\n",
    "X_test_selected = forward_selector.transform(X_test)\n",
    "\n",
    "model = LinearRegression().fit(X_train_selected, y_train)\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Forward Selection MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selection MSE: 1.9735538918399645e+29\n"
     ]
    }
   ],
   "source": [
    "y_test_inv=mms2.inverse_transform(y_test.values.reshape(-1,1))\n",
    "y_pred_inv=mms2.inverse_transform(y_pred.reshape(-1,1))\n",
    "\n",
    "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
    "print(f\"Forward Selection MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 'Type of ownership_Unknown' with p-value 0.9955721379382576\n",
      "Dropping 'State_IL' with p-value 0.98849023058045\n",
      "Dropping 'State_TX' with p-value 0.9837638107622427\n",
      "Dropping 'Industry_Advertising & Public Relations' with p-value 0.9834607572894192\n",
      "Dropping 'Industry_Grocery Stores' with p-value 0.9831497688265312\n",
      "Dropping 'State_KY' with p-value 0.9485517281357971\n",
      "Dropping 'Industry_Food & Beverage Manufacturing' with p-value 0.9469035085111404\n",
      "Dropping 'Sector_Retail & Wholesale' with p-value 0.9382826638922037\n",
      "Dropping 'Sector_Transportation & Logistics' with p-value 0.9414299092194311\n",
      "Dropping 'Industry_Accounting & Tax' with p-value 0.9258525460989905\n",
      "Dropping 'Industry_Investment & Asset Management' with p-value 0.9283726312771816\n",
      "Dropping 'Type of ownership_Subsidiary or Business Segment' with p-value 0.9265050051858008\n",
      "Dropping 'Industry_Shipping & Trucking' with p-value 0.9239391997090518\n",
      "Dropping 'Industry_Broadcast Media' with p-value 0.9211505750467561\n",
      "Dropping 'State_HI' with p-value 0.8990180653862407\n",
      "Dropping 'Industry_Colleges & Universities' with p-value 0.9012302994676564\n",
      "Dropping 'Type of ownership_Self-employed' with p-value 0.891978251826854\n",
      "Dropping 'Type of ownership_Private Practice / Firm' with p-value 0.8948710831641391\n",
      "Dropping 'Industry_Research & Development' with p-value 0.8732742050745085\n",
      "Dropping 'Industry_National Agencies' with p-value 0.8633064607971129\n",
      "Dropping 'Sector_Government & Public Administration' with p-value 0.8937079858592821\n",
      "Dropping 'State_OR' with p-value 0.832293798349684\n",
      "Dropping 'Industry_Film Production' with p-value 0.8264133554111778\n",
      "Dropping 'Industry_Hotels & Resorts' with p-value 0.8094383642601994\n",
      "Dropping 'Sector_Hotels & Travel Accommodation' with p-value 0.8094383642601446\n",
      "Dropping 'State_ID' with p-value 0.8142493047975565\n",
      "Dropping 'Sector_Management & Consulting' with p-value 0.8236974004507931\n",
      "Dropping 'Sector_Education' with p-value 0.8252672495372538\n",
      "Dropping 'Industry_Primary & Secondary Schools' with p-value 0.8367525456630913\n",
      "Dropping 'State_FL' with p-value 0.7850971742330742\n",
      "Dropping 'Type of ownership_Company - Public' with p-value 0.7839300912775576\n",
      "Dropping 'Industry_Metal & Mineral Manufacturing' with p-value 0.7686313107456005\n",
      "Dropping 'Industry_Commercial Equipment Services' with p-value 0.7312259057235166\n",
      "Dropping 'Type of ownership_School / School District' with p-value 0.7015528910387383\n",
      "Dropping 'Seniority_Junior' with p-value 0.7012135291709727\n",
      "Dropping 'Size_51 to 200 Employees' with p-value 0.6824477051509273\n",
      "Dropping 'Size_10000+ Employees' with p-value 0.9724099664888232\n",
      "Dropping 'Size_1 to 50 Employees' with p-value 0.7803726249434133\n",
      "Dropping 'State_NY' with p-value 0.6734318934445135\n",
      "Dropping 'Industry_Pharmaceutical' with p-value 0.6629516713345835\n",
      "Dropping 'Industry_Biotech & Pharmaceuticals' with p-value 0.9679492341010338\n",
      "Dropping 'State_IA' with p-value 0.6483066644524438\n",
      "Dropping 'Industry_Membership Organizations' with p-value 0.6535769990474722\n",
      "Dropping 'State_IN' with p-value 0.6540035872582177\n",
      "Dropping 'Industry_State & Regional Agencies' with p-value 0.6247814490624048\n",
      "Dropping 'State_DE' with p-value 0.6320483157704021\n",
      "Dropping 'Size_Unknown' with p-value 0.616596306526116\n",
      "Dropping 'Big Data/Spark' with p-value 0.6074935199793134\n",
      "Dropping 'State_AR' with p-value 0.5979725491409511\n",
      "Dropping 'Industry_Car & Truck Rental' with p-value 0.5665581432199216\n",
      "Dropping 'Industry_Stock Exchanges' with p-value 0.5734003817165502\n",
      "Dropping 'Size_501 to 1000 Employees' with p-value 0.5380884286956487\n",
      "Dropping 'Industry_Beauty & Personal Accessories Stores' with p-value 0.5711409660437061\n",
      "Dropping 'Sector_Telecommunications' with p-value 0.5801492171368234\n",
      "Dropping 'Industry_Telecommunications Services' with p-value 0.5801492171368257\n",
      "Dropping 'Sector_Real Estate' with p-value 0.6026095826639686\n",
      "Dropping 'Industry_Real Estate' with p-value 0.6026095826639735\n",
      "Dropping 'Industry_Department, Clothing & Shoe Stores' with p-value 0.6603618987681541\n",
      "Dropping 'Industry_Business Consulting' with p-value 0.6632519083542339\n",
      "Dropping 'Sector_--' with p-value 0.6552084608382402\n",
      "Dropping 'Industry_--' with p-value 0.6552084608382692\n",
      "Dropping 'Industry_HR Consulting' with p-value 0.6332950901679673\n",
      "Dropping 'Sector_Human Resources & Staffing' with p-value 0.633295090168005\n",
      "Dropping 'Sector_Construction, Repair & Maintenance Services' with p-value 0.6342137942901868\n",
      "Dropping 'Sector_Insurance' with p-value 0.6364380615942027\n",
      "Dropping 'Sector_Energy, Mining & Utilities' with p-value 0.5936553471137107\n",
      "Dropping 'Industry_Energy & Utilities' with p-value 0.5936553471137112\n",
      "Dropping 'Data Science' with p-value 0.5766584906574589\n",
      "Dropping 'Industry_Restaurants & Cafes' with p-value 0.5737484031528148\n",
      "Dropping 'Sector_Restaurants & Food Service' with p-value 0.5737484031527991\n",
      "Dropping 'Industry_Wholesale' with p-value 0.5817845878943193\n",
      "Dropping 'Industry_General Merchandise & Superstores' with p-value 0.5720146393175045\n",
      "Dropping 'Sector_Financial Services' with p-value 0.5873731785747788\n",
      "Dropping 'Sector_Media & Communication' with p-value 0.5716028218362217\n",
      "Dropping 'Industry_Internet & Web Services' with p-value 0.57654319751376\n",
      "Dropping 'Industry_Software Development' with p-value 0.8371132243735405\n",
      "Dropping 'Industry_Enterprise Software & Network Solutions' with p-value 0.5947823542094434\n",
      "Dropping 'Industry_Machinery Manufacturing' with p-value 0.5427154677770308\n",
      "Dropping 'Sector_Manufacturing' with p-value 0.8211266594925892\n",
      "Dropping 'Industry_Consumer Product Manufacturing' with p-value 0.5917644970263609\n",
      "Dropping 'Industry_Sports & Recreation' with p-value 0.534793507218454\n",
      "Dropping 'Sector_Arts, Entertainment & Recreation' with p-value 0.5347935072185281\n",
      "Dropping 'Industry_Chemical Manufacturing' with p-value 0.5054580177568786\n",
      "Dropping 'Industry_Insurance Agencies & Brokerages' with p-value 0.4770667494052385\n",
      "Dropping 'State_MN' with p-value 0.44697081572996844\n",
      "Dropping 'Industry_Aerospace & Defense' with p-value 0.4351827497947788\n",
      "Dropping 'Sector_Aerospace & Defense' with p-value 0.4351827497948578\n",
      "Dropping 'State_VA' with p-value 0.43041920133368294\n",
      "Dropping 'Sector_Healthcare' with p-value 0.41254682341161153\n",
      "Dropping 'Industry_Health Care Services & Hospitals' with p-value 0.41254682341162086\n",
      "Dropping 'Deep Learning' with p-value 0.371371905087149\n",
      "Dropping 'Revenue_Less than $1 million (USD)' with p-value 0.415084326992885\n",
      "Dropping 'Revenue_$500 million to $1 billion (USD)' with p-value 0.7070616777619393\n",
      "Dropping 'Industry_Home Furniture & Housewares Stores' with p-value 0.3219817478444835\n",
      "Dropping 'State_GA' with p-value 0.32926100925169843\n",
      "Dropping 'Industry_Preschools & Child Care Services' with p-value 0.29958038888918714\n",
      "Dropping 'Industry_Financial Transaction Processing' with p-value 0.2811929682737221\n",
      "Dropping 'Type of ownership_Company - Private' with p-value 0.2906090679245616\n",
      "Dropping 'State_AZ' with p-value 0.2802803460369482\n",
      "Dropping 'State_RI' with p-value 0.27123499070018564\n",
      "Dropping 'Analysis' with p-value 0.24868332489278064\n",
      "Dropping 'State_MO' with p-value 0.2277047460573296\n",
      "Dropping 'Industry_Computer Hardware Development' with p-value 0.2558574818749239\n",
      "Dropping 'Sector_Nonprofit & NGO' with p-value 0.22701082204876166\n",
      "Dropping 'Industry_Civic & Social Services' with p-value 0.22701082204874934\n",
      "Dropping 'Industry_Insurance Carriers' with p-value 0.21753945257650636\n",
      "Dropping 'Industry_Publishing' with p-value 0.2399923425240566\n",
      "Dropping 'Size_5001 to 10000 Employees' with p-value 0.20554413680062594\n",
      "Dropping 'State_NJ' with p-value 0.19194226721381896\n",
      "Dropping 'Industry_Beauty & Wellness' with p-value 0.41397161052596454\n",
      "Dropping 'Sector_Personal Consumer Services' with p-value 0.41397161052596054\n",
      "Dropping 'State_MA' with p-value 0.13892193436768555\n",
      "Dropping 'Seniority_Mid-Level' with p-value 0.1254549544106663\n",
      "Dropping 'Revenue_$5 to $25 million (USD)' with p-value 0.11741381701430872\n",
      "Dropping 'Revenue_$25 to $100 million (USD)' with p-value 0.32925708350712046\n",
      "Dropping 'State_Remote' with p-value 0.12813198297949416\n",
      "Dropping 'State_NE' with p-value 0.15380423157899634\n",
      "Dropping 'State_WA' with p-value 0.12104231014662431\n",
      "Dropping 'Sector_Legal' with p-value 0.11435052161465367\n",
      "Dropping 'Industry_Legal' with p-value 0.11435052161465084\n",
      "Dropping 'Industry_Sporting Goods Stores' with p-value 0.10624450114608816\n",
      "Dropping 'Industry_Information Technology Support Services' with p-value 0.08749632811044232\n",
      "Dropping 'Industry_Electronics Manufacturing' with p-value 0.08432864335228214\n",
      "Dropping 'Industry_Banking & Lending' with p-value 0.08121574841563324\n",
      "Dropping 'Industry_Video Game Publishing' with p-value 0.08382885568976252\n",
      "Dropping 'Sector_Pharmaceutical & Biotechnology' with p-value 0.08853836722286113\n",
      "Dropping 'Industry_Construction' with p-value 0.08678362810817476\n",
      "Dropping 'Industry_Other Retail Stores' with p-value 0.05927958352123314\n",
      "Dropping 'Type of ownership_Government' with p-value 0.05962194046018687\n",
      "Selected features after backward elimination:\n",
      "Index(['const', 'Rating', 'Employeer Estimate', 'Company Age',\n",
      "       'Machine Learning', 'SQL', 'Computer Science', 'Visualization Tool',\n",
      "       'Size_-1', 'Size_1001 to 5000 Employees', 'Size_201 to 500 Employees',\n",
      "       'Type of ownership_-1', 'Type of ownership_College / University',\n",
      "       'Type of ownership_Hospital',\n",
      "       'Type of ownership_Nonprofit Organization', 'Industry_-1',\n",
      "       'Industry_Airlines, Airports & Air Transportation',\n",
      "       'Industry_Pet & Pet Supplies Stores',\n",
      "       'Industry_Transportation Equipment Manufacturing', 'Sector_-1',\n",
      "       'Sector_Information Technology', 'Revenue_$1 to $5 billion (USD)',\n",
      "       'Revenue_$10+ billion (USD)', 'Revenue_$100 to $500 million (USD)',\n",
      "       'Revenue_$5 to $10 billion (USD)', 'Revenue_-1',\n",
      "       'Revenue_Unknown / Non-Applicable', 'State_AK', 'State_AL', 'State_CA',\n",
      "       'State_CO', 'State_CT', 'State_LA', 'State_OH', 'State_PA', 'State_UT',\n",
      "       'State_United States', 'Seniority_Manager/Leadership',\n",
      "       'Seniority_Not Applicable', 'Seniority_Senior'],\n",
      "      dtype='object')\n",
      "Backward Elimination r2_score: 0.333807869231744\n",
      "Backward Elimination MSE: 1941981774.728574\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Add a constant for statsmodels\n",
    "X_with_const = sm.add_constant(X)\n",
    "\n",
    "# Fit the full model\n",
    "model = sm.OLS(y, X_with_const).fit()\n",
    "\n",
    "while True:\n",
    "    # Get the p-values and remove the feature with the highest p-value > 0.05\n",
    "    p_values = model.pvalues\n",
    "    max_p_value = p_values.max()\n",
    "    if max_p_value > 0.05:\n",
    "        excluded_feature = p_values.idxmax()\n",
    "        print(f\"Dropping '{excluded_feature}' with p-value {max_p_value}\")\n",
    "        X_with_const = X_with_const.drop(columns=[excluded_feature])\n",
    "        model = sm.OLS(y, X_with_const).fit()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"Selected features after backward elimination:\")\n",
    "print(X_with_const.columns)\n",
    "\n",
    "# Evaluate the final model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_const, y, test_size=0.2, random_state=42)\n",
    "\n",
    "final_model = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "mse = r2_score(y_test, y_pred)\n",
    "print(f\"Backward Elimination r2_score: {mse}\")\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Backward Elimination MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"Average Salary\",\"Rating\",\"Size\",\"Type of ownership\",\"Industry\",\"Sector\",\"Revenue\",\"Employeer Estimate\",\"State\",\"Company Age\",'Analysis','Machine Learning', 'SQL', 'Computer Science', 'Deep Learning','Big Data/Spark', 'Visualization Tool', 'Data Science',\"Seniority\"]]\n",
    "df2=df[[\"Average Salary\",\"Rating\",\"Revenue\",\"Employeer Estimate\",\"State\",\"Company Age\",'Analysis','Machine Learning', 'SQL', 'Computer Science', 'Deep Learning','Big Data/Spark', 'Visualization Tool', 'Data Science',\"Seniority\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Average Salary', 'Employeer Estimate', 'State', 'Company Age',\n",
       "       'Analysis', 'Machine Learning', 'SQL', 'Computer Science',\n",
       "       'Deep Learning', 'Big Data/Spark', 'Visualization Tool', 'Data Science',\n",
       "       'Seniority'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\testr\\AppData\\Local\\Temp\\ipykernel_11016\\4183182224.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Company Age'] = mms.fit_transform(df2['Company Age'].values.reshape(-1,1))\n",
      "C:\\Users\\testr\\AppData\\Local\\Temp\\ipykernel_11016\\4183182224.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[\"Average Salary\"] = mms2.fit_transform(df2[\"Average Salary\"].values.reshape(-1,1))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "mms=StandardScaler()\n",
    "mms2=StandardScaler()\n",
    "df2['Company Age'] = mms.fit_transform(df2['Company Age'].values.reshape(-1,1))\n",
    "df2[\"Average Salary\"] = mms2.fit_transform(df2[\"Average Salary\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.get_dummies(df2,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df2.drop(\"Average Salary\",axis=1)\n",
    "y=df2[\"Average Salary\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFR=RandomForestRegressor()\n",
    "model=RFR.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.2640802069288636\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "# y_test_inv=mms2.inverse_transform(y_test.values.reshape(-1,1))\n",
    "# y_pred_inv=mms2.inverse_transform(y_pred.reshape(-1,1))\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# accuracy = mean_squared_error(y_test_inv,y_pred_inv)\n",
    "\n",
    "inv_y_true = mms2.inverse_transform(y_test.values.reshape(-1,1))\n",
    "inv_y_pred = mms2.inverse_transform(y_pred.reshape(-1,1))\n",
    "itmse = r2_score(inv_y_true, inv_y_pred)\n",
    "print(\"r2_score:\", itmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\testr\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.3923 - mae: 1.7086 - val_loss: 1.2260 - val_mae: 0.8150 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2144 - mae: 1.2096 - val_loss: 1.1900 - val_mae: 0.8195 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4331 - mae: 0.9371 - val_loss: 1.1821 - val_mae: 0.8200 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1149 - mae: 0.8352 - val_loss: 1.1919 - val_mae: 0.8228 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1058 - mae: 0.8474 - val_loss: 1.1903 - val_mae: 0.8172 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9371 - mae: 0.7739 - val_loss: 1.1792 - val_mae: 0.8125 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9053 - mae: 0.7412 - val_loss: 1.1337 - val_mae: 0.7959 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7648 - mae: 0.6880 - val_loss: 1.1166 - val_mae: 0.7942 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6814 - mae: 0.6603 - val_loss: 1.1252 - val_mae: 0.7987 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6904 - mae: 0.6655 - val_loss: 1.1214 - val_mae: 0.7943 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6366 - mae: 0.6280 - val_loss: 1.1075 - val_mae: 0.7900 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5960 - mae: 0.6050 - val_loss: 1.0920 - val_mae: 0.7823 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6617 - mae: 0.6423 - val_loss: 1.0764 - val_mae: 0.7788 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7133 - mae: 0.6771 - val_loss: 1.0771 - val_mae: 0.7767 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5959 - mae: 0.6265 - val_loss: 1.0621 - val_mae: 0.7688 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5574 - mae: 0.5837 - val_loss: 1.0386 - val_mae: 0.7618 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5148 - mae: 0.5700 - val_loss: 1.0133 - val_mae: 0.7551 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5310 - mae: 0.5865 - val_loss: 1.0040 - val_mae: 0.7535 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5300 - mae: 0.5620 - val_loss: 0.9853 - val_mae: 0.7443 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5135 - mae: 0.5639 - val_loss: 0.9714 - val_mae: 0.7487 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5079 - mae: 0.5577 - val_loss: 0.9833 - val_mae: 0.7538 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5456 - mae: 0.5863 - val_loss: 0.9962 - val_mae: 0.7450 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5018 - mae: 0.5327 - val_loss: 1.0004 - val_mae: 0.7383 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5609 - mae: 0.5905 - val_loss: 0.9350 - val_mae: 0.7317 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4685 - mae: 0.5325 - val_loss: 0.9892 - val_mae: 0.7421 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4741 - mae: 0.5377 - val_loss: 0.9936 - val_mae: 0.7314 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3968 - mae: 0.4846 - val_loss: 1.0069 - val_mae: 0.7287 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4057 - mae: 0.4908 - val_loss: 0.9553 - val_mae: 0.7168 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3810 - mae: 0.4799 - val_loss: 0.9234 - val_mae: 0.7071 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4126 - mae: 0.4975 - val_loss: 0.9426 - val_mae: 0.7078 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4159 - mae: 0.5087 - val_loss: 0.9628 - val_mae: 0.7209 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4288 - mae: 0.5146 - val_loss: 0.9595 - val_mae: 0.7301 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3813 - mae: 0.4795 - val_loss: 0.9645 - val_mae: 0.7319 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4365 - mae: 0.5128 - val_loss: 0.9324 - val_mae: 0.7100 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4263 - mae: 0.5127 - val_loss: 0.9182 - val_mae: 0.7077 - learning_rate: 5.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3864 - mae: 0.4834 - val_loss: 0.9326 - val_mae: 0.7100 - learning_rate: 5.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3660 - mae: 0.4693 - val_loss: 0.9532 - val_mae: 0.7102 - learning_rate: 5.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4145 - mae: 0.4987 - val_loss: 0.9428 - val_mae: 0.7093 - learning_rate: 5.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3779 - mae: 0.4918 - val_loss: 0.9568 - val_mae: 0.7122 - learning_rate: 5.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3640 - mae: 0.4735 - val_loss: 0.9637 - val_mae: 0.7134 - learning_rate: 5.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3764 - mae: 0.4796 - val_loss: 0.9519 - val_mae: 0.7116 - learning_rate: 2.5000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3493 - mae: 0.4560 - val_loss: 0.9514 - val_mae: 0.7123 - learning_rate: 2.5000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3407 - mae: 0.4541 - val_loss: 0.9454 - val_mae: 0.7110 - learning_rate: 2.5000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3312 - mae: 0.4429 - val_loss: 0.9264 - val_mae: 0.7071 - learning_rate: 2.5000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3292 - mae: 0.4596 - val_loss: 0.9215 - val_mae: 0.7074 - learning_rate: 2.5000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3297 - mae: 0.4488 - val_loss: 0.9226 - val_mae: 0.7080 - learning_rate: 1.2500e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3146 - mae: 0.4426 - val_loss: 0.9219 - val_mae: 0.7078 - learning_rate: 1.2500e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3834 - mae: 0.4855 - val_loss: 0.9329 - val_mae: 0.7106 - learning_rate: 1.2500e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2983 - mae: 0.4370 - val_loss: 0.9383 - val_mae: 0.7130 - learning_rate: 1.2500e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3618 - mae: 0.4783 - val_loss: 0.9475 - val_mae: 0.7157 - learning_rate: 1.2500e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3263 - mae: 0.4607 - val_loss: 0.9499 - val_mae: 0.7174 - learning_rate: 6.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3360 - mae: 0.4677 - val_loss: 0.9528 - val_mae: 0.7171 - learning_rate: 6.2500e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3665 - mae: 0.4586 - val_loss: 0.9525 - val_mae: 0.7168 - learning_rate: 6.2500e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3617 - mae: 0.4571 - val_loss: 0.9575 - val_mae: 0.7183 - learning_rate: 6.2500e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3626 - mae: 0.4794 - val_loss: 0.9568 - val_mae: 0.7169 - learning_rate: 6.2500e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3450 - mae: 0.4606 - val_loss: 0.9567 - val_mae: 0.7171 - learning_rate: 3.1250e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3222 - mae: 0.4513 - val_loss: 0.9565 - val_mae: 0.7178 - learning_rate: 3.1250e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3052 - mae: 0.4460 - val_loss: 0.9519 - val_mae: 0.7166 - learning_rate: 3.1250e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3498 - mae: 0.4883 - val_loss: 0.9489 - val_mae: 0.7161 - learning_rate: 3.1250e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2967 - mae: 0.4147 - val_loss: 0.9498 - val_mae: 0.7169 - learning_rate: 3.1250e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2909 - mae: 0.4338 - val_loss: 0.9473 - val_mae: 0.7164 - learning_rate: 1.5625e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3211 - mae: 0.4285 - val_loss: 0.9477 - val_mae: 0.7171 - learning_rate: 1.5625e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3341 - mae: 0.4633 - val_loss: 0.9489 - val_mae: 0.7174 - learning_rate: 1.5625e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3398 - mae: 0.4555 - val_loss: 0.9487 - val_mae: 0.7174 - learning_rate: 1.5625e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3406 - mae: 0.4485 - val_loss: 0.9490 - val_mae: 0.7170 - learning_rate: 1.5625e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3447 - mae: 0.4631 - val_loss: 0.9484 - val_mae: 0.7166 - learning_rate: 1.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3378 - mae: 0.4502 - val_loss: 0.9472 - val_mae: 0.7168 - learning_rate: 1.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3177 - mae: 0.4462 - val_loss: 0.9499 - val_mae: 0.7178 - learning_rate: 1.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3187 - mae: 0.4560 - val_loss: 0.9513 - val_mae: 0.7178 - learning_rate: 1.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3637 - mae: 0.4804 - val_loss: 0.9490 - val_mae: 0.7175 - learning_rate: 1.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3768 - mae: 0.4850 - val_loss: 0.9504 - val_mae: 0.7177 - learning_rate: 1.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3447 - mae: 0.4609 - val_loss: 0.9496 - val_mae: 0.7176 - learning_rate: 1.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3620 - mae: 0.4595 - val_loss: 0.9519 - val_mae: 0.7185 - learning_rate: 1.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3254 - mae: 0.4462 - val_loss: 0.9501 - val_mae: 0.7179 - learning_rate: 1.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3823 - mae: 0.4746 - val_loss: 0.9489 - val_mae: 0.7171 - learning_rate: 1.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2926 - mae: 0.4158 - val_loss: 0.9451 - val_mae: 0.7153 - learning_rate: 1.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3063 - mae: 0.4328 - val_loss: 0.9467 - val_mae: 0.7158 - learning_rate: 1.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3379 - mae: 0.4606 - val_loss: 0.9459 - val_mae: 0.7156 - learning_rate: 1.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3782 - mae: 0.4724 - val_loss: 0.9432 - val_mae: 0.7154 - learning_rate: 1.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3039 - mae: 0.4314 - val_loss: 0.9418 - val_mae: 0.7147 - learning_rate: 1.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3427 - mae: 0.4582 - val_loss: 0.9393 - val_mae: 0.7142 - learning_rate: 1.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2690 - mae: 0.4080 - val_loss: 0.9401 - val_mae: 0.7142 - learning_rate: 1.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4127 - mae: 0.5081 - val_loss: 0.9405 - val_mae: 0.7147 - learning_rate: 1.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3336 - mae: 0.4650 - val_loss: 0.9395 - val_mae: 0.7146 - learning_rate: 1.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3229 - mae: 0.4403 - val_loss: 0.9405 - val_mae: 0.7147 - learning_rate: 1.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3083 - mae: 0.4537 - val_loss: 0.9446 - val_mae: 0.7154 - learning_rate: 1.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3405 - mae: 0.4602 - val_loss: 0.9444 - val_mae: 0.7144 - learning_rate: 1.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3235 - mae: 0.4409 - val_loss: 0.9414 - val_mae: 0.7135 - learning_rate: 1.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3250 - mae: 0.4402 - val_loss: 0.9426 - val_mae: 0.7140 - learning_rate: 1.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2925 - mae: 0.4174 - val_loss: 0.9397 - val_mae: 0.7137 - learning_rate: 1.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3077 - mae: 0.4354 - val_loss: 0.9378 - val_mae: 0.7134 - learning_rate: 1.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3484 - mae: 0.4591 - val_loss: 0.9396 - val_mae: 0.7137 - learning_rate: 1.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3659 - mae: 0.4696 - val_loss: 0.9402 - val_mae: 0.7137 - learning_rate: 1.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3243 - mae: 0.4303 - val_loss: 0.9414 - val_mae: 0.7140 - learning_rate: 1.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3232 - mae: 0.4563 - val_loss: 0.9420 - val_mae: 0.7145 - learning_rate: 1.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3109 - mae: 0.4406 - val_loss: 0.9413 - val_mae: 0.7142 - learning_rate: 1.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3398 - mae: 0.4592 - val_loss: 0.9417 - val_mae: 0.7141 - learning_rate: 1.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3297 - mae: 0.4373 - val_loss: 0.9408 - val_mae: 0.7133 - learning_rate: 1.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3564 - mae: 0.4652 - val_loss: 0.9400 - val_mae: 0.7131 - learning_rate: 1.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3253 - mae: 0.4565 - val_loss: 0.9391 - val_mae: 0.7132 - learning_rate: 1.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3114 - mae: 0.4362 - val_loss: 0.9394 - val_mae: 0.7135 - learning_rate: 1.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3706 - mae: 0.4729 - val_loss: 0.9354 - val_mae: 0.7120 - learning_rate: 1.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3112 - mae: 0.4445 - val_loss: 0.9347 - val_mae: 0.7124 - learning_rate: 1.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3315 - mae: 0.4621 - val_loss: 0.9326 - val_mae: 0.7124 - learning_rate: 1.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3628 - mae: 0.4669 - val_loss: 0.9320 - val_mae: 0.7127 - learning_rate: 1.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3540 - mae: 0.4755 - val_loss: 0.9345 - val_mae: 0.7144 - learning_rate: 1.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3232 - mae: 0.4445 - val_loss: 0.9339 - val_mae: 0.7135 - learning_rate: 1.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3143 - mae: 0.4410 - val_loss: 0.9331 - val_mae: 0.7125 - learning_rate: 1.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3084 - mae: 0.4350 - val_loss: 0.9321 - val_mae: 0.7127 - learning_rate: 1.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3389 - mae: 0.4549 - val_loss: 0.9334 - val_mae: 0.7123 - learning_rate: 1.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3903 - mae: 0.4755 - val_loss: 0.9333 - val_mae: 0.7128 - learning_rate: 1.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3023 - mae: 0.4205 - val_loss: 0.9339 - val_mae: 0.7129 - learning_rate: 1.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3014 - mae: 0.4327 - val_loss: 0.9317 - val_mae: 0.7116 - learning_rate: 1.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3285 - mae: 0.4516 - val_loss: 0.9322 - val_mae: 0.7118 - learning_rate: 1.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3384 - mae: 0.4379 - val_loss: 0.9326 - val_mae: 0.7123 - learning_rate: 1.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3124 - mae: 0.4363 - val_loss: 0.9335 - val_mae: 0.7137 - learning_rate: 1.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3129 - mae: 0.4469 - val_loss: 0.9325 - val_mae: 0.7135 - learning_rate: 1.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2846 - mae: 0.4226 - val_loss: 0.9333 - val_mae: 0.7130 - learning_rate: 1.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2991 - mae: 0.4331 - val_loss: 0.9345 - val_mae: 0.7133 - learning_rate: 1.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3684 - mae: 0.4851 - val_loss: 0.9336 - val_mae: 0.7131 - learning_rate: 1.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3131 - mae: 0.4411 - val_loss: 0.9323 - val_mae: 0.7131 - learning_rate: 1.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3309 - mae: 0.4586 - val_loss: 0.9322 - val_mae: 0.7133 - learning_rate: 1.0000e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3647 - mae: 0.4614 - val_loss: 0.9302 - val_mae: 0.7120 - learning_rate: 1.0000e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3438 - mae: 0.4697 - val_loss: 0.9312 - val_mae: 0.7131 - learning_rate: 1.0000e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2986 - mae: 0.4257 - val_loss: 0.9305 - val_mae: 0.7126 - learning_rate: 1.0000e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3540 - mae: 0.4815 - val_loss: 0.9294 - val_mae: 0.7121 - learning_rate: 1.0000e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3323 - mae: 0.4556 - val_loss: 0.9300 - val_mae: 0.7121 - learning_rate: 1.0000e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3174 - mae: 0.4485 - val_loss: 0.9295 - val_mae: 0.7125 - learning_rate: 1.0000e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3110 - mae: 0.4360 - val_loss: 0.9290 - val_mae: 0.7122 - learning_rate: 1.0000e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3123 - mae: 0.4409 - val_loss: 0.9299 - val_mae: 0.7132 - learning_rate: 1.0000e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3163 - mae: 0.4353 - val_loss: 0.9301 - val_mae: 0.7130 - learning_rate: 1.0000e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3639 - mae: 0.4687 - val_loss: 0.9300 - val_mae: 0.7129 - learning_rate: 1.0000e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3223 - mae: 0.4503 - val_loss: 0.9311 - val_mae: 0.7138 - learning_rate: 1.0000e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2995 - mae: 0.4232 - val_loss: 0.9284 - val_mae: 0.7135 - learning_rate: 1.0000e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3430 - mae: 0.4484 - val_loss: 0.9274 - val_mae: 0.7130 - learning_rate: 1.0000e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3881 - mae: 0.4874 - val_loss: 0.9272 - val_mae: 0.7134 - learning_rate: 1.0000e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3259 - mae: 0.4592 - val_loss: 0.9260 - val_mae: 0.7124 - learning_rate: 1.0000e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3173 - mae: 0.4492 - val_loss: 0.9256 - val_mae: 0.7124 - learning_rate: 1.0000e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2795 - mae: 0.4136 - val_loss: 0.9246 - val_mae: 0.7115 - learning_rate: 1.0000e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3588 - mae: 0.4777 - val_loss: 0.9253 - val_mae: 0.7116 - learning_rate: 1.0000e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2764 - mae: 0.4063 - val_loss: 0.9249 - val_mae: 0.7119 - learning_rate: 1.0000e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3407 - mae: 0.4719 - val_loss: 0.9243 - val_mae: 0.7117 - learning_rate: 1.0000e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3418 - mae: 0.4747 - val_loss: 0.9252 - val_mae: 0.7117 - learning_rate: 1.0000e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2861 - mae: 0.4292 - val_loss: 0.9274 - val_mae: 0.7120 - learning_rate: 1.0000e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3242 - mae: 0.4670 - val_loss: 0.9285 - val_mae: 0.7123 - learning_rate: 1.0000e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3241 - mae: 0.4486 - val_loss: 0.9294 - val_mae: 0.7129 - learning_rate: 1.0000e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3767 - mae: 0.4782 - val_loss: 0.9288 - val_mae: 0.7129 - learning_rate: 1.0000e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2985 - mae: 0.4346 - val_loss: 0.9274 - val_mae: 0.7123 - learning_rate: 1.0000e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3452 - mae: 0.4625 - val_loss: 0.9273 - val_mae: 0.7129 - learning_rate: 1.0000e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3149 - mae: 0.4373 - val_loss: 0.9275 - val_mae: 0.7128 - learning_rate: 1.0000e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3923 - mae: 0.4910 - val_loss: 0.9292 - val_mae: 0.7135 - learning_rate: 1.0000e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3006 - mae: 0.4212 - val_loss: 0.9278 - val_mae: 0.7128 - learning_rate: 1.0000e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2971 - mae: 0.4255 - val_loss: 0.9250 - val_mae: 0.7120 - learning_rate: 1.0000e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3208 - mae: 0.4355 - val_loss: 0.9257 - val_mae: 0.7119 - learning_rate: 1.0000e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3398 - mae: 0.4536 - val_loss: 0.9259 - val_mae: 0.7117 - learning_rate: 1.0000e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2964 - mae: 0.4328 - val_loss: 0.9232 - val_mae: 0.7110 - learning_rate: 1.0000e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3100 - mae: 0.4274 - val_loss: 0.9220 - val_mae: 0.7107 - learning_rate: 1.0000e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3276 - mae: 0.4493 - val_loss: 0.9205 - val_mae: 0.7100 - learning_rate: 1.0000e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3485 - mae: 0.4722 - val_loss: 0.9194 - val_mae: 0.7093 - learning_rate: 1.0000e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3281 - mae: 0.4520 - val_loss: 0.9209 - val_mae: 0.7097 - learning_rate: 1.0000e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3671 - mae: 0.4797 - val_loss: 0.9203 - val_mae: 0.7096 - learning_rate: 1.0000e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3250 - mae: 0.4458 - val_loss: 0.9194 - val_mae: 0.7101 - learning_rate: 1.0000e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3158 - mae: 0.4369 - val_loss: 0.9203 - val_mae: 0.7096 - learning_rate: 1.0000e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3387 - mae: 0.4688 - val_loss: 0.9227 - val_mae: 0.7101 - learning_rate: 1.0000e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3599 - mae: 0.4656 - val_loss: 0.9236 - val_mae: 0.7097 - learning_rate: 1.0000e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3295 - mae: 0.4345 - val_loss: 0.9226 - val_mae: 0.7099 - learning_rate: 1.0000e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3759 - mae: 0.4711 - val_loss: 0.9230 - val_mae: 0.7103 - learning_rate: 1.0000e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3149 - mae: 0.4432 - val_loss: 0.9247 - val_mae: 0.7112 - learning_rate: 1.0000e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3223 - mae: 0.4593 - val_loss: 0.9235 - val_mae: 0.7103 - learning_rate: 1.0000e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3162 - mae: 0.4278 - val_loss: 0.9237 - val_mae: 0.7109 - learning_rate: 1.0000e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3175 - mae: 0.4514 - val_loss: 0.9243 - val_mae: 0.7109 - learning_rate: 1.0000e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2905 - mae: 0.4245 - val_loss: 0.9222 - val_mae: 0.7106 - learning_rate: 1.0000e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3725 - mae: 0.4818 - val_loss: 0.9234 - val_mae: 0.7107 - learning_rate: 1.0000e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3097 - mae: 0.4273 - val_loss: 0.9232 - val_mae: 0.7106 - learning_rate: 1.0000e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3027 - mae: 0.4380 - val_loss: 0.9246 - val_mae: 0.7108 - learning_rate: 1.0000e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3274 - mae: 0.4417 - val_loss: 0.9224 - val_mae: 0.7099 - learning_rate: 1.0000e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2960 - mae: 0.4222 - val_loss: 0.9217 - val_mae: 0.7099 - learning_rate: 1.0000e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2879 - mae: 0.4134 - val_loss: 0.9212 - val_mae: 0.7102 - learning_rate: 1.0000e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3411 - mae: 0.4510 - val_loss: 0.9194 - val_mae: 0.7097 - learning_rate: 1.0000e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3110 - mae: 0.4474 - val_loss: 0.9204 - val_mae: 0.7100 - learning_rate: 1.0000e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3054 - mae: 0.4293 - val_loss: 0.9203 - val_mae: 0.7107 - learning_rate: 1.0000e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3114 - mae: 0.4459 - val_loss: 0.9210 - val_mae: 0.7102 - learning_rate: 1.0000e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3455 - mae: 0.4581 - val_loss: 0.9190 - val_mae: 0.7097 - learning_rate: 1.0000e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3777 - mae: 0.4775 - val_loss: 0.9181 - val_mae: 0.7095 - learning_rate: 1.0000e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2895 - mae: 0.4262 - val_loss: 0.9181 - val_mae: 0.7094 - learning_rate: 1.0000e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3238 - mae: 0.4416 - val_loss: 0.9180 - val_mae: 0.7088 - learning_rate: 1.0000e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2859 - mae: 0.4306 - val_loss: 0.9188 - val_mae: 0.7088 - learning_rate: 1.0000e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2998 - mae: 0.4284 - val_loss: 0.9180 - val_mae: 0.7089 - learning_rate: 1.0000e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3343 - mae: 0.4526 - val_loss: 0.9148 - val_mae: 0.7074 - learning_rate: 1.0000e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3194 - mae: 0.4383 - val_loss: 0.9148 - val_mae: 0.7071 - learning_rate: 1.0000e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2794 - mae: 0.4254 - val_loss: 0.9141 - val_mae: 0.7062 - learning_rate: 1.0000e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3122 - mae: 0.4297 - val_loss: 0.9152 - val_mae: 0.7058 - learning_rate: 1.0000e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2960 - mae: 0.4143 - val_loss: 0.9161 - val_mae: 0.7061 - learning_rate: 1.0000e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3218 - mae: 0.4508 - val_loss: 0.9167 - val_mae: 0.7071 - learning_rate: 1.0000e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2792 - mae: 0.4105 - val_loss: 0.9180 - val_mae: 0.7078 - learning_rate: 1.0000e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2865 - mae: 0.4325 - val_loss: 0.9182 - val_mae: 0.7077 - learning_rate: 1.0000e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3259 - mae: 0.4549 - val_loss: 0.9194 - val_mae: 0.7085 - learning_rate: 1.0000e-05\n",
      "Epoch 198/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3193 - mae: 0.4482 - val_loss: 0.9164 - val_mae: 0.7076 - learning_rate: 1.0000e-05\n",
      "Epoch 199/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3390 - mae: 0.4570 - val_loss: 0.9133 - val_mae: 0.7068 - learning_rate: 1.0000e-05\n",
      "Epoch 200/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3330 - mae: 0.4497 - val_loss: 0.9121 - val_mae: 0.7066 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(X_train.shape[1],)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m43,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">263,173</span> (1.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m263,173\u001b[0m (1.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,425</span> (341.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m87,425\u001b[0m (341.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,852</span> (683.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m174,852\u001b[0m (683.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.8429 - mae: 0.7019 - val_loss: 1.0452 - val_mae: 0.7385\n",
      "Epoch 2/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6587 - mae: 0.6481 - val_loss: 1.1071 - val_mae: 0.7443\n",
      "Epoch 3/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5588 - mae: 0.5819 - val_loss: 1.0803 - val_mae: 0.7422\n",
      "Epoch 4/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5469 - mae: 0.5881 - val_loss: 0.9999 - val_mae: 0.7297\n",
      "Epoch 5/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4450 - mae: 0.4909 - val_loss: 1.0272 - val_mae: 0.7164\n",
      "Epoch 6/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4405 - mae: 0.5171 - val_loss: 1.0219 - val_mae: 0.7180\n",
      "Epoch 7/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3377 - mae: 0.4430 - val_loss: 1.0248 - val_mae: 0.7422\n",
      "Epoch 8/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3109 - mae: 0.4061 - val_loss: 1.0481 - val_mae: 0.7212\n",
      "Epoch 9/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2764 - mae: 0.4000 - val_loss: 0.9485 - val_mae: 0.6857\n",
      "Epoch 10/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2408 - mae: 0.3692 - val_loss: 1.0394 - val_mae: 0.7428\n",
      "Epoch 11/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2663 - mae: 0.3748 - val_loss: 0.9511 - val_mae: 0.6916\n",
      "Epoch 12/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2036 - mae: 0.3447 - val_loss: 0.9742 - val_mae: 0.7405\n",
      "Epoch 13/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2235 - mae: 0.3482 - val_loss: 1.0396 - val_mae: 0.7426\n",
      "Epoch 14/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1910 - mae: 0.3287 - val_loss: 1.0304 - val_mae: 0.7194\n",
      "Epoch 15/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1859 - mae: 0.3211 - val_loss: 1.0053 - val_mae: 0.7240\n",
      "Epoch 16/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1436 - mae: 0.2895 - val_loss: 0.9858 - val_mae: 0.7271\n",
      "Epoch 17/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1801 - mae: 0.3022 - val_loss: 1.0125 - val_mae: 0.7349\n",
      "Epoch 18/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1486 - mae: 0.2771 - val_loss: 1.0261 - val_mae: 0.7339\n",
      "Epoch 19/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1786 - mae: 0.3159 - val_loss: 1.0301 - val_mae: 0.7266\n",
      "Epoch 20/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1510 - mae: 0.2809 - val_loss: 1.0980 - val_mae: 0.7410\n",
      "Epoch 21/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1846 - mae: 0.3118 - val_loss: 1.0644 - val_mae: 0.7393\n",
      "Epoch 22/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1431 - mae: 0.2792 - val_loss: 1.0911 - val_mae: 0.7464\n",
      "Epoch 23/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1283 - mae: 0.2701 - val_loss: 1.1419 - val_mae: 0.7688\n",
      "Epoch 24/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1604 - mae: 0.2794 - val_loss: 1.0667 - val_mae: 0.7389\n",
      "Epoch 25/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1656 - mae: 0.2840 - val_loss: 1.0582 - val_mae: 0.7192\n",
      "Epoch 26/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1214 - mae: 0.2469 - val_loss: 1.0700 - val_mae: 0.7205\n",
      "Epoch 27/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1338 - mae: 0.2628 - val_loss: 1.0082 - val_mae: 0.7227\n",
      "Epoch 28/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1257 - mae: 0.2510 - val_loss: 1.0534 - val_mae: 0.7391\n",
      "Epoch 29/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1312 - mae: 0.2688 - val_loss: 1.0084 - val_mae: 0.7233\n",
      "Epoch 30/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1373 - mae: 0.2683 - val_loss: 1.0602 - val_mae: 0.7421\n",
      "Epoch 31/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1087 - mae: 0.2327 - val_loss: 0.9967 - val_mae: 0.7184\n",
      "Epoch 32/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1084 - mae: 0.2429 - val_loss: 1.0205 - val_mae: 0.7288\n",
      "Epoch 33/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0941 - mae: 0.2150 - val_loss: 0.9898 - val_mae: 0.7064\n",
      "Epoch 34/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1412 - mae: 0.2463 - val_loss: 1.0184 - val_mae: 0.7235\n",
      "Epoch 35/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1277 - mae: 0.2434 - val_loss: 1.0693 - val_mae: 0.7404\n",
      "Epoch 36/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1271 - mae: 0.2509 - val_loss: 1.1177 - val_mae: 0.7669\n",
      "Epoch 37/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1002 - mae: 0.2259 - val_loss: 1.1286 - val_mae: 0.7655\n",
      "Epoch 38/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0858 - mae: 0.2135 - val_loss: 1.0664 - val_mae: 0.7579\n",
      "Epoch 39/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1113 - mae: 0.2228 - val_loss: 1.0852 - val_mae: 0.7403\n",
      "Epoch 40/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0761 - mae: 0.2002 - val_loss: 0.9985 - val_mae: 0.7060\n",
      "Epoch 41/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1236 - mae: 0.2367 - val_loss: 1.0848 - val_mae: 0.7454\n",
      "Epoch 42/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1366 - mae: 0.2425 - val_loss: 1.0948 - val_mae: 0.7694\n",
      "Epoch 43/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1207 - mae: 0.2370 - val_loss: 1.0888 - val_mae: 0.7513\n",
      "Epoch 44/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1032 - mae: 0.2247 - val_loss: 1.0314 - val_mae: 0.7263\n",
      "Epoch 45/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1144 - mae: 0.2336 - val_loss: 1.0166 - val_mae: 0.7210\n",
      "Epoch 46/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1124 - mae: 0.2214 - val_loss: 1.0992 - val_mae: 0.7570\n",
      "Epoch 47/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0770 - mae: 0.1886 - val_loss: 1.0899 - val_mae: 0.7581\n",
      "Epoch 48/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0987 - mae: 0.2158 - val_loss: 1.0604 - val_mae: 0.7506\n",
      "Epoch 49/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1032 - mae: 0.2235 - val_loss: 1.1025 - val_mae: 0.7360\n",
      "Epoch 50/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1023 - mae: 0.2199 - val_loss: 1.1353 - val_mae: 0.7704\n",
      "Epoch 51/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1049 - mae: 0.2265 - val_loss: 1.2247 - val_mae: 0.8213\n",
      "Epoch 52/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0862 - mae: 0.2125 - val_loss: 1.0657 - val_mae: 0.7482\n",
      "Epoch 53/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1001 - mae: 0.2158 - val_loss: 1.0452 - val_mae: 0.7289\n",
      "Epoch 54/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0955 - mae: 0.2155 - val_loss: 1.0562 - val_mae: 0.7563\n",
      "Epoch 55/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0857 - mae: 0.2111 - val_loss: 1.0575 - val_mae: 0.7384\n",
      "Epoch 56/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0914 - mae: 0.2151 - val_loss: 1.0270 - val_mae: 0.7265\n",
      "Epoch 57/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0659 - mae: 0.1847 - val_loss: 1.0671 - val_mae: 0.7364\n",
      "Epoch 58/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1387 - mae: 0.2389 - val_loss: 1.0778 - val_mae: 0.7530\n",
      "Epoch 59/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1072 - mae: 0.2186 - val_loss: 1.0289 - val_mae: 0.7389\n",
      "Epoch 60/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0884 - mae: 0.2050 - val_loss: 1.0957 - val_mae: 0.7501\n",
      "Epoch 61/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0928 - mae: 0.2110 - val_loss: 1.0505 - val_mae: 0.7414\n",
      "Epoch 62/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0608 - mae: 0.1827 - val_loss: 1.0798 - val_mae: 0.7497\n",
      "Epoch 63/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0804 - mae: 0.1950 - val_loss: 1.0966 - val_mae: 0.7646\n",
      "Epoch 64/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1186 - mae: 0.2336 - val_loss: 1.0578 - val_mae: 0.7407\n",
      "Epoch 65/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1055 - mae: 0.2151 - val_loss: 1.0205 - val_mae: 0.7326\n",
      "Epoch 66/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1074 - mae: 0.2196 - val_loss: 1.0960 - val_mae: 0.7277\n",
      "Epoch 67/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0805 - mae: 0.2024 - val_loss: 1.0427 - val_mae: 0.7218\n",
      "Epoch 68/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0892 - mae: 0.2019 - val_loss: 1.0549 - val_mae: 0.7619\n",
      "Epoch 69/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0830 - mae: 0.1907 - val_loss: 1.0793 - val_mae: 0.7628\n",
      "Epoch 70/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1089 - mae: 0.2218 - val_loss: 1.0530 - val_mae: 0.7328\n",
      "Epoch 71/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0833 - mae: 0.1902 - val_loss: 1.0579 - val_mae: 0.7455\n",
      "Epoch 72/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0716 - mae: 0.1854 - val_loss: 1.0621 - val_mae: 0.7318\n",
      "Epoch 73/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0889 - mae: 0.2066 - val_loss: 1.0603 - val_mae: 0.7233\n",
      "Epoch 74/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0826 - mae: 0.1986 - val_loss: 1.0702 - val_mae: 0.7634\n",
      "Epoch 75/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1253 - mae: 0.2128 - val_loss: 1.2217 - val_mae: 0.7974\n",
      "Epoch 76/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0799 - mae: 0.1947 - val_loss: 1.2736 - val_mae: 0.8065\n",
      "Epoch 77/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1196 - mae: 0.2252 - val_loss: 1.1138 - val_mae: 0.7487\n",
      "Epoch 78/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0775 - mae: 0.1905 - val_loss: 1.1615 - val_mae: 0.7732\n",
      "Epoch 79/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0575 - mae: 0.1666 - val_loss: 1.1163 - val_mae: 0.7623\n",
      "Epoch 80/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0750 - mae: 0.1944 - val_loss: 1.1041 - val_mae: 0.7555\n",
      "Epoch 81/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0522 - mae: 0.1646 - val_loss: 1.1111 - val_mae: 0.7591\n",
      "Epoch 82/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1045 - mae: 0.2000 - val_loss: 1.1102 - val_mae: 0.7543\n",
      "Epoch 83/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1060 - mae: 0.2120 - val_loss: 1.1767 - val_mae: 0.7941\n",
      "Epoch 84/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0806 - mae: 0.1917 - val_loss: 1.0894 - val_mae: 0.7279\n",
      "Epoch 85/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1204 - mae: 0.2118 - val_loss: 1.1383 - val_mae: 0.7420\n",
      "Epoch 86/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0601 - mae: 0.1653 - val_loss: 1.0858 - val_mae: 0.7500\n",
      "Epoch 87/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0545 - mae: 0.1607 - val_loss: 1.1492 - val_mae: 0.7737\n",
      "Epoch 88/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1158 - mae: 0.2272 - val_loss: 1.1538 - val_mae: 0.7650\n",
      "Epoch 89/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0670 - mae: 0.1733 - val_loss: 1.1922 - val_mae: 0.7879\n",
      "Epoch 90/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0905 - mae: 0.1982 - val_loss: 1.0980 - val_mae: 0.7435\n",
      "Epoch 91/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0752 - mae: 0.1761 - val_loss: 1.0952 - val_mae: 0.7515\n",
      "Epoch 92/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0548 - mae: 0.1678 - val_loss: 1.1605 - val_mae: 0.7824\n",
      "Epoch 93/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0691 - mae: 0.1771 - val_loss: 1.1753 - val_mae: 0.7693\n",
      "Epoch 94/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0750 - mae: 0.1884 - val_loss: 1.2014 - val_mae: 0.7824\n",
      "Epoch 95/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0764 - mae: 0.1867 - val_loss: 1.1214 - val_mae: 0.7556\n",
      "Epoch 96/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0973 - mae: 0.2015 - val_loss: 1.1584 - val_mae: 0.7793\n",
      "Epoch 97/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1201 - mae: 0.2038 - val_loss: 1.1472 - val_mae: 0.7583\n",
      "Epoch 98/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0489 - mae: 0.1497 - val_loss: 1.2064 - val_mae: 0.7912\n",
      "Epoch 99/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0910 - mae: 0.1980 - val_loss: 1.0823 - val_mae: 0.7497\n",
      "Epoch 100/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0844 - mae: 0.1898 - val_loss: 1.1038 - val_mae: 0.7635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x225afe5dcd0>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "r2 score: 0.19187493510767306\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled target values\n",
    "y_test_inv = mms2.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "y_pred_inv = mms2.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate Mean Absolute Error on the original scale\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "mae = r2_score(y_test_inv, y_pred_inv)\n",
    "print(f\"r2 score: {mae}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
